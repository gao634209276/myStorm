http://ifeve.com/wp-content/uploads/2014/03/Getting-Started-With-Storm-Jonathan-Leibiusky-Gabriel-E_1276.pdf
Storm是一个分布式的，可靠的，容错的数据流处理系统。
	它会把工作任务委托给不同类型的组件，每个组件负责处理一项简单特定的任务。
	Storm集群的输入流由一个被称作spout的组件管理，spout把数据传递给bolt，
	bolt要么把数据保存到某种存储器，要么把数据传递给其它的bolt。
	你可以想象一下，一个Storm集群就是在一连串的bolt之间转换spout传过来的数据。


	想像播音员读的字幕作为你的数据输入流。你可以用一个spout读取一个文件（或者socket，通过HTTP，或者别的方法）。
	文本行被spout传给一个bolt，再被bolt按单词切割。单词流又被传给另一个bolt，在这里每个单词与一张政治人名列表比较。
	每遇到一个匹配的名字，第二个bolt为这个名字在数据库的计数加1。
	你可以随时查询数据库查看结果， 而且这些计数是随着数据到达实时更新的。所有组件（spouts和bolts）及它们之间的关系请参考拓扑图1-1
	http://ifeve.com/storm%e5%85%a5%e9%97%a8%e7%bf%bb%e8%af%91getting-started-with-storm/figure-1-1-a-simple-topology/
有哪些典型的Storm应用案例？
	数据处理流
		正如上例所展示的，不像其它的流处理系统，Storm不需要中间队列。
	连续计算
		连续发送数据到客户端，使它们能够实时更新并显示结果，如网站指标。
	分布式远程过程调用
		频繁的CPU密集型操作并行化。

Storm组件
对于一个Storm集群，一个连续运行的主节点组织若干节点工作。

	在Storm集群中，有两类节点：主节点master node和工作节点worker nodes。
		主节点运行着一个叫做Nimbus的守护进程。这个守护进程负责在集群中分发代码，为工作节点分配任务，并监控故障。
		Supervisor守护进程作为拓扑的一部分运行在工作节点上。一个Storm拓扑结构在不同的机器上运行着众多的工作节点。
	因为Storm在Zookeeper或本地磁盘上维持所有的集群状态，守护进程可以是无状态的而且失效或重启时不会影响整个系统的健康（见图1-2）
	Numbus-->zookeeper-->zookeeper

	在系统底层，Storm使用了zeromq(0mq, zeromq(http://www.zeromq.org))。
	这是一种先进的，可嵌入的网络通讯库，它提供的绝妙功能使Storm成为可能。下面列出一些zeromq的特性。
	    一个并发架构的Socket库
	    对于集群产品和超级计算，比TCP要快
	    可通过inproc（进程内）, IPC（进程间）, TCP和multicast(多播协议)通信
	    异步I / O的可扩展的多核消息传递应用程序
		利用扇出(fanout), 发布订阅（PUB-SUB）,管道（pipeline）, 请求应答（REQ-REP），等方式实现N-N连接
	注意:Storm只用了push/pull sockets

Storm的特性
在所有这些设计思想与决策中，有一些非常棒的特性成就了独一无二的Storm。
	简化编程    如果你曾试着从零开始实现实时处理，你应该明白这是一件多么痛苦的事情。使用Storm，复杂性被大大降低了。
	使用一门基于JVM的语言开发会更容易，但是你可以借助一个小的中间件，在Storm上使用任何语言开发。有现成的中间件可供选择，当然也可以自己开发中间件。
	容错         Storm集群会关注工作节点状态，如果宕机了必要的时候会重新分配任务。
	可扩展    所有你需要为扩展集群所做的工作就是增加机器。Storm会在新机器就绪时向它们分配任务。
	可靠的    所有消息都可保证至少处理一次。如果出错了，消息可能处理不只一次，不过你永远不会丢失消息。
	快速        速度是驱动Storm设计的一个关键因素
	事务性   你可以为几乎任何计算得到恰好一次消息语义。


创建一个Storm工程和我们的第一个Storm拓扑结构。
----------------------------------------------
Storm的操作模式
	本地模式
	在本地模式下，Storm拓扑结构运行在本地计算机的单一JVM进程上。
	这个模式用于开发、测试以及调试，因为这是观察所有组件如何协同工作的最简单方法。
	在这种模式下，我们可以调整参数，观察我们的拓扑结构如何在不同的Storm配置环境下运行。
	要在本地模式下运行，我们要下载Storm开发依赖，以便用来开发并测试我们的拓扑结构。
	我们创建了第一个Storm工程以后，很快就会明白如何使用本地模式了。
	NOTE: 在本地模式下，跟在集群环境运行很像。
	不过很有必要确认一下所有组件都是线程安全的，
	而当把它们部署到远程模式时它们可能会运行在不同的JVM进程甚至不同的物理机上，这个时候它们之间没有直接的通讯或共享内存。
	我们要在本地模式运行本章的所有例子。

	远程模式
	在远程模式下，我们向Storm集群提交拓扑，它通常由许多运行在不同机器上的流程组成。
	远程模式不会出现调试信息， 因此它也称作生产模式。
	不过在单一开发机上建立一个Storm集群是一个好主意，可以在部署到生产环境之前，用来确认拓扑在集群环境下没有任何问题。

Hello World
	我们在这个工程里创建一个简单的拓扑，数单词数量。
	我们可以把这个看作Storm的“Hello World”。
	不过，这是一个非常强大的拓扑，因为它能够扩展到几乎无限大的规模，而且只需要做一些小修改，就能用它构建一个统计系统。
	举个例子，我们可以修改一下工程用来找出Twitter上的热点话题。

Spout
	See: WordReader.java
	spout WordReader类实现了IRichSpout接口。
	我们将在第四章看到更多细节。WordReader负责从文件按行读取文本，并把文本行提供给第一个bolt。

	第一个被调用的spout方法都是public void open(Map conf, TopologyContext context, SpoutOutputCollector collector)。
	它接收如下参数：配置对象，在定义topology对象是创建；TopologyContext对象，包含所有拓扑数据；
	还有SpoutOutputCollector对象，它能让我们发布交给bolts处理的数据。下面的代码主是这个方法的实现。

	我们在这个方法里创建了一个FileReader对象，用来读取文件。
	接下来我们要实现public void nextTuple()，我们要通过它向bolts发布待处理的数据。
	在这个例子里，这个方法要读取文件并逐行发布数据。

	NOTE: Values是一个ArrarList实现，它的元素就是传入构造器的参数。

	nextTuple()会在同一个循环内被ack()和fail()周期性的调用。
	没有任务时它必须释放对线程的控制，其它方法才有机会得以执行。
		因此nextTuple的第一行就要检查是否已处理完成。
		如果完成了，为了降低处理器负载，会在返回前休眠一毫秒。
		如果任务完成了，文件中的每一行都已被读出并分发了。

	NOTE:元组(tuple)是一个具名值列表，它可以是任意java对象（只要它是可序列化的）。
	默认情况，Storm会序列化字符串、字节数组、ArrayList、HashMap和HashSet等类型。


Bolts
	现在我们有了一个spout，用来按行读取文件并每行发布一个元组，还要创建两个bolts，用来处理它们。
	bolt最重要的方法是void execute(Tuple input)，每次接收到元组时都会被调用一次，还会再发布若干个元组。
	NOTE: 只要必要，bolt或spout会发布若干元组。
	当调用nextTuple或execute方法时，它们可能会发布0个、1个或许多个元组。你将在第五章学习更多这方面的内容。

	第一个bolt，WordNormalizer，负责得到并标准化每行文本。它把文本行切分成单词，大写转化成小写，去掉头尾空白符。
		See: WordNormalizer.java
	首先我们要声明bolt的出参：
		public void declareOutputFields(OutputFieldsDeclarer declarer){
		这里我们声明bolt将发布一个名为“word”的域。
    下一步我们实现public void execute(Tuple input)，处理传入的元组：
		第一行从元组读取值。值可以按位置或名称读取。
		接下来值被处理并用collector对象发布。
		最后，每次都调用collector对象的ack()方法确认已成功处理了一个元组。

	NOTE:通过这个例子，我们了解了在一次execute调用中发布多个元组。
		如果这个方法在一次调用中接收到句子“This is the Storm book”，它将会发布五个元组。

	下一个bolt，WordCounter，负责为单词计数。这个拓扑结束时（cleanup()方法被调用时），我们将显示每个单词的数量。
	NOTE: 这个例子的bolt什么也没发布，它把数据保存在map里，但是在真实的场景中可以把数据保存到数据库。
	See :WordCounter.java
	execute方法使用一个map收集单词并计数。
	拓扑结束时，将调用clearup()方法打印计数器map。
	（虽然这只是一个例子，但是通常情况下，当拓扑关闭时，你应当使用cleanup()方法关闭活动的连接和其它资源。）


主类
	你可以在主类中创建拓扑和一个本地集群对象，以便于在本地测试和调试。
	LocalCluster可以通过Config对象，让你尝试不同的集群配置。
	比如，当使用不同数量的工作进程测试你的拓扑时，如果不小心使用了某个全局变量或类变量，你就能够发现错误。（更多内容请见第三章）

	NOTE：所有拓扑节点的各个进程必须能够独立运行，而不依赖共享数据（也就是没有全局变量或类变量），
	因为当拓扑运行在真实的集群环境时，这些进程可能会运行在不同的机器上。
	接下来，TopologyBuilder将用来创建拓扑，它决定Storm如何安排各节点，以及它们交换数据的方式。

		TopologyBuilder builder = new TopologyBuilder();
		builder.setSpout("word-reader", new WordReader());
		builder.setBolt("word-normalizer", new WordNormalizer()).shuffleGrouping("word-reader");
		builder.setBolt("word-counter", new WordCounter()).shuffleGrouping("word-normalizer");
	在spout和bolts之间通过shuffleGrouping方法连接。
	这种分组方式决定了Storm会以随机分配方式从源节点向目标节点发送消息。

	下一步，创建一个包含拓扑配置的Config对象，它会在运行时与集群配置合并，并通过prepare方法发送给所有节点。
		Config conf = new Config();
		conf.put("wordsFile", args[0]);
		conf.setDebug(true);
	由spout读取的文件的文件名，赋值给wordFile属性。
	由于是在开发阶段，设置debug属性为true，Strom会打印节点间交换的所有消息，以及其它有助于理解拓扑运行方式的调试数据。
	正如之前讲过的，你要用一个LocalCluster对象运行这个拓扑。
	在生产环境中，拓扑会持续运行，不过对于这个例子而言，你只要运行它几秒钟就能看到结果。

		LocalCluster cluster = new LocalCluster();
		cluster.submitTopology("Getting-Started-Topologie", conf, builder.createTopology());
		Thread.sleep(2000);
		cluster.shutdown();
	调用createTopology和submitTopology，运行拓扑，休眠两秒钟（拓扑在另外的线程运行），然后关闭集群。

观察运行情况

	你已经为运行你的第一个拓扑准备好了。
	在这个目录下面创建一个文件，/src/main/resources/words.txt，
	一个单词一行，然后用下面的命令运行这个拓扑：
	mvn exec:java -Dexec.mainClass=”TopologyMain” -Dexec.args=”src/main/resources/words.txt。
	举个例子，如果你的words.txt文件有如下内容：
	Storm test are great is an Storm simple application but very powerful really Storm is great
	你应该会在日志中看到类似下面的内容：
	is: 2 application: 1 but: 1 great: 1 test: 1 simple: 1 Storm: 3 really: 1 are: 1 great: 1 an: 1 powerful: 1 very: 1

	在这个例子中，每类节点只有一个实例。
	但是如果你有一个非常大的日志文件呢？
	你能够很轻松的改变系统中的节点数量实现并行工作。这个时候，你就要创建两个WordCounter实例。

	builder.setBolt("word-counter", new WordCounter(),2).shuffleGrouping("word-normalizer");

	程序返回时，你将看到：
	— 单词数 【word-counter-2】 — application: 1 is: 1 great: 1 are: 1 powerful: 1 Storm: 3
	— 单词数 [word-counter-3] — really: 1 is: 1 but: 1 great: 1 test: 1 simple: 1 an: 1 very: 1
	棒极了！修改并行度实在是太容易了（当然对于实际情况来说，每个实例都会运行在单独的机器上）。

	不过似乎有一个问题：单词is和great分别在每个WordCounter各计数一次。怎么会这样？
	当你调用shuffleGrouping时，就决定了Storm会以随机分配的方式向你的bolt实例发送消息。
	在这个例子中，理想的做法是相同的单词问题发送给同一个WordCounter实例。
	你把shuffleGrouping(“word-normalizer”)换成fieldsGrouping(“word-normalizer”, new Fields(“word”))就能达到目的。
	试一试，重新运行程序，确认结果。 你将在后续章节学习更多分组方式和消息流类型。

结论

	我们已经讨论了Storm的本地和远程操作模式之间的不同，以及Storm的强大和易于开发的特性。
	你也学习了一些Storm的基本概念，我们将在后续章节深入讲解它们。

参考:http://ifeve.com/getting-started-with-storm-2/